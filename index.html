<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title>Geophysical Data Processing</title>
        <style>
        
        
        </style>
    </head>
    <body>
          <h1>Geophysical Data Processing</h1>
          <h2 id="Contents">Contents</h2>
          <ul>
               <h3 id="Digitization">Digitization</h3>
              <li>Spectral analysis</li>
              <li>Waveform processing
                  
              </li>
              </ul>
              
    <h3>Digitization</h3>
    <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRELxsryHEu2d9bU0zwRN3Yv454zzXilr6xIj107_Q6_spuiy4osw" width=300">
    <p><strong>Digitizing </strong> is the process of converting information into a <strong>digital format</strong>.
	In this format, information is organized into discrete units of data (called <strong>bit</strong>/ s) that can be separately addressed (usually in multiple-bit groups called byte s). <br> 
	This is the binary data that computers and many devices with computing capacity (such as<strong> digital camera</strong>/ s and <strong>digital hearing aid </strong>/s) can process.

Text and images can be digitized similarly: a <strong>scanner</strong> captures an image (which may be an image of text) <br> 
and converts it to an image file, such as a bitmap . An optical character recognition (<strong> OCR</strong> ) program analyzes a text image for light and dark areas in order to identify each alphabetic letter or numeric digit, and converts each character into an <strong>ASCII</strong> code.<br>
    <strong>Digitizing </strong>information makes it easier to preserve, access, and share. For example, an original historical document may only be accessible to people who visit its physical location, but if the document content is digitized, it can be made available to people worldwide.<br> 
	There is a growing trend towards digitization of historically and culturally significant data.
    <strong>The most important concepts you will ever need in processing observations are <em>spatial</em> and <em>temporal frequencies. </em></strong><br>
	
    <img src="digitization1.png" width="300"/>
	
	   <h3 id="Spectral analysis">Spectral analysis</h3>

        <thead>
            <ol>
                <li>Fourier analysis</li>
                <li>Sampling frequency</li>
                <li>Spectra in space and time domain</li>
            </ol>
        </thead>
      <h4 id:"Fourier analysis">Fourier analysis:</h4>
      <P><strong>Fourier analysis </strong> is the study of the way general functions may be represented or approximated by sums of simpler trigonometric functions. Fourier analysis grew from the study of <strong><em>Fourier series</em></strong>, and is named after<strong><em> Joseph Fourier</em></strong>, who showed that representing <br> 
	  a function as a sum of trigonometric functions greatly simplifies the study of <strong>heat transfer.</strong><br>
      
      Today, the subject of Fourier analysis encompasses a vast spectrum of mathematics. In the sciences and engineering, the process of decomposing a function into oscillatory components is often called Fourier analysis, while the operation of rebuilding the function from these pieces is <br> 
	  known as <strong>Fourier synthesis</strong>. For example, determining what component frequencies are present in a musical note would involve computing the Fourier transform of a sampled musical note. One could then re-synthesize the same sound by including the frequency components as revealed in the Fourier analysis.
	  In mathematics, the term Fourier analysis often refers to the study of both operations.<Br>
      <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Bass_Guitar_Time_Signal_of_open_string_A_note_%2855_Hz%29.png/400px-Bass_Guitar_Time_Signal_of_open_string_A_note_%2855_Hz%29.png" width="300">
     
</P>
<h4 id="Sampling frequency">Sampling frequency:</h4> 
<p>
<strong>The sampling frequency </strong>or <strong>sampling rate</strong>, fs, is the average number of samples obtained in one second (samples per second), thus<strong> fs = 1/T.</strong><br>

Reconstructing a continuous function from samples is done by interpolation algorithms. The<strong> Whittaker–Shannon interpolation formula </strong>is mathematically equivalent to an ideal <strong>lowpass filter</strong> whose input is a sequence of Dirac delta functions that are modulated (multiplied) by the sample values. When the time interval between <br>
adjacent samples is a constant (T), the sequence of delta functions is called a <strong>Dirac comb</strong>. Mathematically, the modulated Dirac comb is equivalent to the product of the comb function with s(t). That purely mathematical abstraction is sometimes referred to as impulse sampling.<br>
Most sampled signals are not simply stored and reconstructed. But the fidelity of a theoretical reconstruction is a customary measure of the effectiveness of sampling. That fidelity is reduced when s(t) contains frequency components whose periodicity is smaller than two samples; or equivalently the ratio of cycles to samples exceeds ½ . <br>
The quantity<em> ½ cycles/sample × <strong>fs</strong> samples/sec = <strong>fs</strong>/2 cycles/sec (<strong>hertz</strong>)</em> is known as the <strong>Nyquist frequency </strong>of the sampler. Therefore, s(t) is usually the output of a lowpass filter, functionally known as an <em>anti-aliasing </em>filter. Without an anti-aliasing filter, frequencies higher <br>than the Nyquist frequency will influence the samples in a way that is misinterpreted by the interpolation process.
</p>
</body>
       
